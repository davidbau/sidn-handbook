<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Steering</title>

<!-- Bootstrap CSS Imports -->
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet"
integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">

<!-- Google Font Imports -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap"
rel="stylesheet">

<!-- Mathjax -->
<script id="MathJax-script" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js"></script>

<!-- Bootstrap JS -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.min.js"></script>

<!-- Auto Table of Contents -->
<link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css"/>
<script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script>

</head>

<body data-bs-spy="scroll" data-bs-target="#toc">
<nav class="navbar navbar-dark bg-dark">
<div class="container-fluid">
<ul class="navbar-nav ml-auto">
 <li class="nav-item">
  <a class="navbar-brand" href="/">A History of Activation Steering</a>
 </li>
</ul>
</div>
</nav>

<div class="container">
<div class="row">
<div class="col-2 position-fixed pt-5">
<nav id="toc" data-toggle="toc"></nav>
</div>
<div class="col-2"></div>
<main class="col-8">

<h1 class="mt-5">A History of Activation Steering</h1>

<h5>November 24, 2024 â€¢ <em>Alex Loftus and Rohit Gandikota</em></h5>

<p>
In late 2024, researchers made significant breakthroughs in controlling large language models through a technique called activation steering. This technique enables targeted modification of model behavior by intervening in the internal activations of transformer neural networks. The development of activation steering spans multiple papers that build on each other, starting with fundamental work in understanding model representations and culminating in practical applications for improving model truthfulness and type prediction.
</p>

<h2>Origins in Representation Understanding</h2>

<p>
The story begins with the paper "Representation Surgery" by Singh et al., which investigates how code language models learn and represent types. The authors discovered that models contain robust, generalizable mechanisms for tasks like type prediction that can be accessed and modified through their internal activations.
</p>

<blockquote class="blockquote">
"We show that by editing intermediate computations (activations) of the model, we can recover performance on type prediction despite the presence of distractors."
<address>- Singh et al.</address>
</blockquote>

<p>
A key finding was that these mechanisms transfer across programming languages - Python steering vectors work effectively for TypeScript and vice versa. This suggested that models learn fundamental task representations that transcend surface syntax.
</p>

<h2>The Development of Steering Techniques</h2>

<p>
Building on these insights, Li et al. formalized the concept of "steering vectors" - directions in activation space that correspond to desired model behaviors. Their work developed systematic methods for:
</p>

<ol>
<li>Identifying relevant attention heads through linear probing</li>
<li>Computing steering vectors that capture task-relevant transformations</li>
<li>Applying targeted interventions during model inference</li>
</ol>

<p>
A crucial innovation was focusing interventions on specific attention heads rather than the full residual stream. This allowed for more precise control while minimizing unintended effects on other model capabilities.
</p>

<img src="/api/placeholder/400/300" alt="Diagram showing attention head selection and steering" class="mx-auto d-block">

<h2>Application to Truthful Generation</h2>

<p>
The techniques culminated in "Inference-Time Intervention" by Li et al., which applied activation steering to make language models more truthful. Their key insight was that models often contain latent knowledge of truth even when they generate false statements.
</p>

<blockquote class="blockquote">
Evidence from several directions suggests that LLMs sometimes "know" more than they "say".
<address>- Li et al.</address>
</blockquote>

<p>
The authors demonstrated that by steering model activations along truth-correlated directions, they could significantly improve performance on the TruthfulQA benchmark while maintaining model fluency and capabilities.
</p>

<h2>Common Themes and Technical Foundations</h2>

<p>
Across these papers, several key technical elements emerge:
</p>

<h3>Activation Spaces and Linear Probing</h3>

<p>
All three papers use linear probing to identify relevant subspaces within model activations. For a given head \(h\) in layer \(l\), they examine the activation vector \(x_l^h\) and train linear classifiers of the form:
</p>

\[ p_\theta(x_l^h)=\operatorname{sigmoid}(\langle \theta, x_l^h \rangle) \]

<p>
This reveals which heads contain task-relevant information and provides directions for steering.
</p>

<h3>Minimal Intervention Principle</h3>

<p>
The papers share a commitment to minimal intervention - making the smallest possible changes to achieve the desired effect. This manifests in:
</p>

<ul>
<li>Targeting specific attention heads rather than full layers</li>
<li>Using simple linear transformations</li>
<li>Carefully calibrating intervention strength</li>
</ul>

<h2>Current Research Directions</h2>

<p>
The field continues to develop in several directions:
</p>

<ul>
<li>Understanding the geometry of activation spaces and how different behaviors are encoded</li>
<li>Developing more precise and controllable steering methods</li>
<li>Applying steering to new tasks and model architectures</li>
<li>Investigating the theoretical foundations of why steering works</li>
</ul>

<p>
The rapid progress in activation steering demonstrates the power of understanding and manipulating neural networks' internal representations. As our understanding grows, these techniques promise to give us ever more precise control over large language models' behavior.
</p>

</main>
</div>
</div>
</body>
</html>