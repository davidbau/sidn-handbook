<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Structure and Interpretation of Deep Networks</title>

<!-- Bootstrap CSS Imports -->
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet"
integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">

<!-- Google Font Imports -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap"
rel="stylesheet">

<!-- Custom CSS Imports -->
<link rel="stylesheet" href="/css/style.css">

<!-- Mathjax -->
<script sid="MathJax-script" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js" integrity="sha512-6FaAxxHuKuzaGHWnV00ftWqP3luSBRSopnNAA2RvQH1fOfnF/A1wOfiUWF7cLIOFcfb1dEhXwo5VG3DAisocRw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<!-- jQuery -->
<script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>

<!-- Bootstrap JS -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.min.js" integrity="sha256-3gQJhtmj7YnV1fmtbVcnAV6eI4ws0Tr48bVZCThtCGQ=" crossorigin="anonymous"></script>

<!-- Auto Table of Contents -->
<link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css"
/>
<script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script>

</head>

<body data-bs-spy="scroll" data-bs-target="#toc">
<nav class="navbar navbar-dark bg-dark">
<div class="container-fluid">
<ul class="navbar-nav mr-auto">
 <li class="nav-item active">
  <a class="nav-link" href="/icl/index.html">Automatic Circuit Discovery</a>
 </li>
</ul>
<ul class="navbar-nav ml-auto">
 <li class="nav-item">
  <a class="navbar-brand" href="/">Structure and Interpretation of Deep Networks</a>
 </li>
</ul>
</div>
</nav>

<div class="container">
<div class="row">
<div class="col-2 position-fixed pt-5">
<nav id="toc" data-toggle="toc"></nav>
</div>
<div class="col-2"></div>
<main class="col-8">
<h1 class="mt-5">Automatic Circuit Discovery</h1>


<div>
  <h5>November 6, 2024 â€¢ <em>David Atkinson, Sri Harsha</em></h5>

  <p>"In-context learning" (ICL) identifies to a phenomenon in which a language model shows decreasing loss as one or more task examples are added to its context window. The modern era of ICL begins with Brown et al., (2020) who extend the multi-task learning https://link.springer.com/article/10.1023/a:1007379606734, scaling law (Kaplan, Hestness), and  meta-learning https://proceedings.mlr.press/v70/finn17a.html literatures with a massively scaled version of GPT-2 (Radford et al., 2019). Although GPT-2 showed early signs of ICL, the new model, GPT-3, displays state-of-the-art performance on a wide variety of NLP benchmarks, without relying on any finetuning.</p>

  <p>The ICL literature has expanded rapidly since the publication of Brown, et. al, (2020), with investigations into TODO, TODO, TODO, . (For a full survey, see Dong et al., (2024).) Of particular relevance to us is the induction heads phenomenon (LINK), which we've covered in previous weeks (LINK).</p>

  <p>This week, we'll discuss two papers which attempt to characterize <i>how</i> ICL works in large language models.</p>

  <h2>
    Function Vectors in Large Language Models
  </h2>
  <p>
    <a href="https://arxiv.org/abs/2310.15213">This paper</a> was published at
    ICLR 2024 by a group of researchers from Northeastern University, led by Eric Todd.<br />
  </p>

  <h3>Section</h3>

  <!-- <img src="images/acdc_alg.png" style="max-width:100%; width:1000px;" class="mx-auto d-block"> -->

  <h3>Discussion</h3>

  <h2>
    What learning algorithm is in-context learning? Investigations with linear models
  </h2>

  TODO

  <h2>Code Resources</h2>
  <p>For function vectors, see <a href="https://colab.research.google.com/drive/1TB1FJX5TxBXGzBBaSvRxSY_E5OPz4jQ3?usp=sharing">this</a> notebook from Callum McDougal and the <a href="https://www.arena.education/">ARENA</a> team (with associated <a href="https://colab.research.google.com/drive/1xHd-58Tksidc8EgQ9B2HDZhLrJZWc7Lf?usp=sharing">answers</a>).

  
</main>
</div>
</div>
</body>
</html>

</div>
